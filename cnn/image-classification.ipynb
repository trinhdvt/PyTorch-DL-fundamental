{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2f0acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fd414",
   "metadata": {},
   "source": [
    "### Load data CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4226232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/cifar-10/\"\n",
    "\n",
    "transform = Compose([ToTensor(), \n",
    "                     Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf5875",
   "metadata": {},
   "source": [
    "### Create a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b82fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:0, 2:1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "train_set = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "val_set = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3128dfef",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e976e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZTElEQVR4nO2de5BdVZWHv0UeBOhgQxIhhkgSCAoKJDE8RIISDK/S4SEqjDJoIUGFKZzCGvEJPnDE8sUIinFgAEdeykMcoSQESlAQaBDSQJAECEUyeUObRAghZM0f90YDnrW6+3b37Yb9+6pSub1+vfdZ9/Rd99y711lrm7sjhHj9s0V/OyCEaA4KdiEKQcEuRCEo2IUoBAW7EIWgYBeiEAb3ZLCZHQ6cDwwC/svdv5X9/vCR5iPGVWtPP54M3LLavMWweMgQGxRqW20dP+3tWkaG2ra8sdI+OHnPXMvqUFu0ZkGotQyPU6KtoRL/QdclY4LTC+RXgyxp+3Jg3yYZ0xd0BPb1yZh1DAk1T5716jUbQm39C8kBn0+0iL8E9pfBN7pVSdZont3MBgGPAzOARcB9wAnu/mg0ZtxU8y+3VWufODQ52Phq87a7x0E7asgbQm3SniNC7Zhpnwi1GXZapf2NbB2OuYtbQ+3fb3t/qL1zehye8SiI3qrmJ2OC0wtAS6JlbyBrA/u+yZhG2Zhovw7sC5MxjzEm1F4iDuhbb1sWak/PSw74QKJF3BTYV4K/VB3sPfkYvy+wwN2fdPf1wFXAUT2YTwjRh/Qk2McAz2z286K6TQgxAOnzBTozm2lmbWbWtmZFXx9NCBHRk2BfDIzd7Oed6rZX4O6z3H2qu08dPqoHRxNC9IieBPt9wEQzG29mQ4HjgRt7xy0hRG/TcOrN3TeY2enAb6ml3i5x90eyMYNIVnc/kAz8ZLV59e7xyujqPVeF2lNLYm3BvRfF2vTqdN4JUw4OxxyQJMp+ND3OGMxP1rrvC5V4hXynZEx8FmFlorUmWmOr7hMSba9QaUvOyH/86h8+bALQMrbSXGNU/PqYc378dxk6OZnz3kTrSLSIyI0kudajPLu730ScBBBCDCB0B50QhaBgF6IQFOxCFIKCXYhCULALUQg9Wo3vLsuAHwbaIafG4+YE+bq9J09JjhanTx76/NOxduOTsXbkmZX29rPjtNCMfeeGWkeoQFLQx6JEi5JQRyRjdky0dybatuyQqNH5zxJ9L4bKXRwTarN/1Rpq9xx9abVwbOzFfhckJT57xtL6LCf6VKJFUXh7MqYBdGUXohAU7EIUgoJdiEJQsAtRCAp2IQqhqavxf10Mf/hStbbLN+Jxp3+k2n7BtUk/n6wN0D6JltXtBVUAf/x0vOKetZDqSLTvJVrGjMCerYFnbam2TfuRxKvxnwqapL2X3cIx+yQ5iBVJ97r2scELBIBLq83JCXnr6FjrmBZrf85W3JM5m1Vdoiu7EIWgYBeiEBTsQhSCgl2IQlCwC1EICnYhCqGpqTeWAudWS08kwy74p0DIqkW2i6VdovwU8ESWsrui2rw4adT2sTuS+RL/d2hw65RoR5jkKbMbcS+87CXym39sJvw3XgjmHE9cvHQ3cS+/47MmhVk9VPTMx88OR9wa7mkEiy9MDpVVKD2TaNH2Ob2MruxCFIKCXYhCULALUQgKdiEKQcEuRCEo2IUohB6l3sxsIbAGeBnY4O5TG54sSGsBcQVb0g+Mk2NpQ7IX0n4XxNo9UWuy+YkfGUmF3ZofxNqnk62Loo1y70zcaA8q1ADGJdqDyZz7BBVxHUljtSs5Lp7QkoOlBHO+FFfRLb7whni6hcmhWhNtAOxg3Bt59oPdPdsSTAgxANDHeCEKoafB7sAtZna/mc3sDYeEEH1DTz/GH+jui83sjcBsM3vM3V9xg2j9TUBvBEL0Mz26srv74vr/y4HrqdiW291nufvUHi3eCSF6TMPBbmbbmNnwTY+BQ4GHe8sxIUTvYu7e2ECzCdSu5lD7OnCFuwc1bX8b09jBvh7YL0/GZPsWJdVmb/lJrJ0S2N+eHGpl0rBx5r1x1djz7fGceydpxaiAKqsqfFeifSrRogo7gNHsXGlvTzo9fnTum+MJ9z4oOdp5idYA2RObnmjBNmUA3J1oUUVcg9Vw7l6ZqGz4O7u7Pwns3eh4IURzUepNiEJQsAtRCAp2IQpBwS5EISjYhSiEhlNvDR2s0dTbkYE9S3VklWgdiRY1twSI9vlKmkN+IKlQa00OdXGyjV3avDDw5W3JXmMfTKbL0orJU2NcYH+MEeGYd9+2RzzhIS8mR7s3lqLXyO7JdB9KtKwh6dJEa9J+bhCn3nRlF6IQFOxCFIKCXYhCULALUQgKdiEKobnbP2VknkQr6//S4LGuSbRrE+2WwD4+me7TyXzJKv4Wk2NtdLLd0a6B/cTEjYmJlpG1VYu0DayKB92yW2OOXJqsxgccdVKsJYkLLjo1EaPXxwBBV3YhCkHBLkQhKNiFKAQFuxCFoGAXohAU7EIUwsBJvcWtyWobTFWRFSVkJD3oGJJohwb2rCAnK464LJYGnxFrB2Y+BmRb9szo/nRAY6c/2kELgPOy5m9vCpWLTjoi1CZyc6U9SxsuTLT0RGav4QGAruxCFIKCXYhCULALUQgKdiEKQcEuRCEo2IUohE5Tb2Z2CfA+YLm7v71u2x64mlqrsYXAh9z9uT7zMkpfXZGMSarG0jKvrHdda2DPqu+yCrtke5/1SZ+5hRNibafAPowdwjE3syzUWuND8etEW5BoMW9ItHj/pHFJD7rWwJ79mTcQV9/tfcbjofbQnsmkX0206LWapYhHBfbfxUO6cmW/FDj8VbazgDnuPhGYU/9ZCDGA6TTY6/utP/sq81H8/ZaQy4Cje9ctIURv0+h39h3cfUn98VJIPiMKIQYEPb5d1t096wdvZjOBmT09jhCiZzR6ZV9mZqMB6v8vj37R3We5+1R3n9rgsYQQvUCjwX4jsKmL10nAr3rHHSFEX9Hp9k9mdiXwHmAksAw4G7iBWlLpzcDT1FJvr17Eq5qreXtNZeyYaFmVWpRayZoQZumTqIqOfNuoD6ZldttUWkclyyormBtqf0yO9IMXEvG7gf3yZMz8i2Nt99NC6cOPxrV00Y5du7NXOGYq54faBn4SaoPZOdTaiPOlS4Lzv5Y4zfeYP1Fpv2KfRSxre7Fy+6dOv7O7+wmBdEhnY4UQAwfdQSdEISjYhSgEBbsQhaBgF6IQFOxCFMLAaTg5UMhSZe2BPSsD+k4snZSk17ZLplzIiFAbGaR4Bid/6geTY/0gu4Pi9kSLOjpm5WZUp5MAOHTLUOpI2lhGmdSWJN04mM+F2o48HWq7hflGmM5HQi1q3fksi8MR29t7K+13Et+7piu7EIWgYBeiEBTsQhSCgl2IQlCwC1EICnYhCuG1nXrLvM/23epItHQzsoCkcWSeaoqrpAYnnb7WJhVbOwXaSlaFY+58IJTg7tmxlm2Y1tC+Z98Mlf1a45zovyUzRluzZQ0x70waWGYvj6/x0VCbwH3JyDGV1vuSF9ZhHJzMV42u7EIUgoJdiEJQsAtRCAp2IQpBwS5EIby2V+MbWvGlsRX3RknaxQ1/7txQW7fu+FDbdeSgeNLgLzo4yRicMuWwUPv4lHjcgripMO2/fbLS/ptrzosn5IZQmbYh/qMdxsdC7btcWmlvZGclgCWJtjDRdkr62kV/mqz/X9sLl1Xal2yMPdSVXYhCULALUQgKdiEKQcEuRCEo2IUoBAW7EIXQaerNzC4B3gcsd/e3123nAKfw91KIL7j7TX3l5IAnSa+NWPuVUPvFhbuE2sjt4vTac7vGx1sbNF1bMH99OGbcxKGhNqw1Pta06W8MtR0PqNZuPvaMcMzG624Itbufiv14NEivAUwO7OOC4hOARUnvt5YkZDYk2n8n+d6dAvsR4QgYtlX1XmRXbNERjunKlf1S4PAK+/fdfVL9X7mBLsRrhE6D3d3vADrdtFEIMbDpyXf2081srpldYmZZ52MhxACg0WD/MbALMInaHYRhw2wzm2lmbWbW1uCxhBC9QEPB7u7L3P1ld98I/BTYN/ndWe4+1d3j7vVCiD6noWA3s9Gb/XgM8HDvuCOE6Cu6knq7EngPMNLMFgFnA+8xs0mAUyv2ObXvXIwZMz6uXRo3bZ9QG7wuftq/uybb0yhg/JmhtOqpafG4FfFWQssmbhNqS5fEaaNV7Y9XC+2PhmMeWZOUxK39Syhdu09cEjd0SvU2VBuvS3raJfwh2nqL2nfKiCgruiJJr+2ezDcjKbVsTbSOZM7qJBrsy7eTUdUhtxXvDkd0GuzufkKF+eLOxgkhBha6g06IQlCwC1EICnYhCkHBLkQhKNiFKISmNpwcM+JN/OtRn6zUhh0Up3GGTd6j0n7w+PHhmJbhsR9JkRrHjj491Oacf1W10P7neML2OL1GS+LJyj+F0qoVcbUZK6sbPZKkmmBEosV+cGdc0bf+zmjONyTHSkhSby8kw24O7E98IxmUdZVMGnB+8uRYuzOZMqqHO4Drk1FRPd9fwxG6sgtRCAp2IQpBwS5EISjYhSgEBbsQhaBgF6IQmpp623HcaD538Zebechu89iKOHUBqwL7/zZ2sKTYjHlZOuy4WGo9oNreEVe9QZIeZFmiZUTnKrI3TrYnWvgCz175P0q0pCTuotZkXFTaBjwSZJB/PeTucMy5zKi0r05c0JVdiEJQsAtRCAp2IQpBwS5EISjYhSiEpq7GvxZY0Z4VHzSTbNX6J7HUEfVBezmZLyjwGUgkr9RHfpWMO6ja/I6z4iH3P5PMF2yvBUA27sjuj7t/UTzkx8HzWp4cRld2IQpBwS5EISjYhSgEBbsQhaBgF6IQFOxCFEJXtn8aC1wO7EBtu6dZ7n6+mW0PXA2Mo7YF1Ifc/bm+c7V7rOf/Qm1oktYa3B5vd7S+Rx41i9fpZj0zE21sogWZyPbklfqWpD9da1K8NC/pXbfVVrG2LOiX+LaozRywLmi85xvjMV25sm8AznT3PYD9gdPMbA/gLGCOu08E5tR/FkIMUDoNdndf4u4P1B+vAeYBY4CjgMvqv3YZcHQf+SiE6AW69Z3dzMZR62F7D7CDu2/64LKU2sd8IcQApcvBbmYtwLXAZ9z9FTXy7u7Uvs9XjZtpZm1m1rZixYoeOSuEaJwuBbuZDaEW6D939+vq5mVmNrqujya4LdfdZ7n7VHefOmrUqN7wWQjRAJ0Gu5kZtSXeee7+vc2kG4GT6o9PArJyBCFEP9OVqrd3AScC7Wb2YN32BeBbwDVmdjK1JmYf6hMPgWcD+1qeCsd0+OxQ2zHpq/Z8V50STWW/C2Ptnt/G2rbBdk1DkmMtSarXPj52r1A7ZuzcUItqEQG+FGxttf/0eEzU0u7R5PLdabC7++8BC+RDOhsvhBgY6A46IQpBwS5EISjYhSgEBbsQhaBgF6IQXhMNJ7cP7C0E++YAS29fHGo3r7gz1LZuif14PtuuSfScrCljxp9iabvDqu1ZeeYxSRXdBxkWarECtyfauw6utmfFfFfeVW1/NnmN6souRCEo2IUoBAW7EIWgYBeiEBTsQhSCgl2IQnhNpN4aYeS4MaE2/uCgFAqY3B6n5f5wbnXt0js+F/txfyzluZr5iXZFNmkTeWei3d3AfF+MpRm8IdQmnxW/jOcHzUXvq2y1UmNdVPYFfJ97Q+3weBjJtm1MC463MvFxUVDwuT7piqoruxCFoGAXohAU7EIUgoJdiEJQsAtRCE1djd9I3ONtbbCdDUBrsHXO4KRj3IQJE0Jt7Zrur7hnzPtJImbFHVln7YnddqP5dDQwZqdEWxNL35geb8vF7smcX6o2b5EUPF0dtzaEpNDk5gNi7YhkygMDe0eSFXju2MCH78ZjdGUXohAU7EIUgoJdiEJQsAtRCAp2IQpBwS5EIXSaejOzscDl1LZkdmCWu59vZucAp/D3BNIX3P2mbK4tgK0DbWVHPG5okHpbzq/DMb+4+vhQOz2W0ne/jYH9+Y5kUKNFK/HuVQOH7mcpIfhbAvCxRFuaaFmDt32rzRuzJnRZEU+yydkT34m1C+JsL5OCXRI/TlzM9fBW1T0WB/Vk+ydqf9Iz3f0BMxsO3G9mm16K33f35CkKIQYKXdnrbQmwpP54jZnNg+QtRwgxIOnWd3YzGwdMBu6pm043s7lmdomZbdfbzgkheo8uB7uZtQDXAp9x99XAj4FdgEnUrvyVN+qZ2UwzazOzthUrsvtDhRB9SZeC3cyGUAv0n7v7dQDuvszdX3b3jcBPCZZC3H2Wu09196mjRo3qLb+FEN2k02A3MwMuBua5+/c2s4/e7NeOAR7uffeEEL1FV1bj3wWcCLSb2YN12xeAE8xsErV03ELg1M4mWss67mJepbbkmSfDce3VQ/jZbXEO7epbOvOmmii9NqA4I9HO7+VjnR1LQ/eMtfXHBULWW69RknRYWKW2MhlzTaJlyeUGtwf7YVDxuWeQXgOYNbfa/lJSPdqV1fjfA1XFdmlOXQgxsNAddEIUgoJdiEJQsAtRCAp2IQpBwS5EITS14eTql1Yxe8lllVr7Xf8Tjls7vzoFcfufkoNlTQNf4xySpJrm9Hbq7fJYWp9Vju0T2O/riTMB4xMtanDZ6Cu/wfRa1kD0oeB1fH3SwHLU2Gr78qHxGF3ZhSgEBbsQhaBgF6IQFOxCFIKCXYhCULALUQhNTb29+NdVzL+3OsU2eHhc4TMyaBo4bY/4WHM+G2vbxhKrEy3isGQ/t982WC50SJS6AiZPjrU5UUVcoym5LIXZmmhRqilrUpmlUjMaaXx5cKL9c6I12kA0q/YL9gr8VrL33d6HVdufHRSP0ZVdiEJQsAtRCAp2IQpBwS5EISjYhSgEBbsQhdDc1NtfXmLBTdUptpagigdgUeDljkFKDuCoG2JtZdJssCPxY90d1fa7G03HJMxJqsPmfD4ZOLLavPVF8ZDnz0nm+3AsvS1JUe0a/G2GJYe6PtjzDGB9lsKMKtsgbiy5Lhmze6L1BVHKMTlZ7UGl38bkeenKLkQhKNiFKAQFuxCFoGAXohAU7EIUQqer8WY2DLgD2LL++79097PNbDxwFTACuB840d3XZ3ONGAYfDwokHktWwVsD+4ZIAEZPibWlD8TavGRlfWPlPrX9QFIgQXWLP57viIe84+uxtijJXDxyXqIdWm3fOini+eZRsTYv0W71WHs62sppSTyG0YmWFCg13J8u6+UXMHiravtLyeW7K1f2F4Hp7r43te2ZDzez/YHzgO+7+67U3D25W94KIZpKp8HuNTa9Zw2p/3NgOvDLuv0y4Oi+cFAI0Tt0dX/2QfUdXJcDs4EngA5331RJvAgY0yceCiF6hS4Fu7u/7O6TqN2rtC/w1q4ewMxmmlmbmbWtbfQ7jRCix3RrNd7dO4DbgXcCrWa2aYFvJ6DyPlh3n+XuU919aktLT1wVQvSEToPdzEaZWWv98VbADGAetaA/rv5rJwHJnc1CiP7G3JO8BWBme1FbgBtE7c3hGnf/mplNoJZ6257arfwfdfcXs7kmjTa/JVizX/S5+K7/K79bfXf/lUlxxHNJMcN2Sdrludmx9nws9T5BQQtQ+yIV0WDPu5BpiZYUXWwbpN5WJz3tdk7yOe+fHmvZqfrhk9X2Vf+ZDErSg6xItKxf36hEuy6wZ731osKmmeCPuVVJnebZ3X0uFU/f3Z8kf9kJIQYQuoNOiEJQsAtRCAp2IQpBwS5EISjYhSiETlNvvXowsxXA0/UfRxJ3CGsm8uOVyI9X8lrzY2d3r0z0NTXYX3FgszZ3n9ovB5cf8qNAP/QxXohCULALUQj9Geyz+vHYmyM/Xon8eCWvGz/67Tu7EKK56GO8EIXQL8FuZoeb2Z/NbIGZndUfPtT9WGhm7Wb2oJm1NfG4l5jZcjN7eDPb9mY228zm1//frp/8OMfMFtfPyYNmdmQT/BhrZreb2aNm9oiZnVG3N/WcJH409ZyY2TAzu9fMHqr78dW6fbyZ3VOPm6vNbGi3Jnb3pv6jVir7BDABGAo8BOzRbD/qviwERvbDcQ8CpgAPb2b7NnBW/fFZwHn95Mc5wGebfD5GA1Pqj4cDjwN7NPucJH409ZwABrTUHw8B7gH2B64Bjq/bLwI+1Z15++PKvi+wwN2f9Frr6auApFHw6w93vwN49lXmo/h7I+imNPAM/Gg67r7E3R+oP15DrTnKGJp8ThI/morX6PUmr/0R7GOAZzb7uT+bVTpwi5ndb2Yz+8mHTezg7pvaaiwFduhHX043s7n1j/l9/nVic8xsHLX+CffQj+fkVX5Ak89JXzR5LX2B7kB3nwIcAZxmZgf1t0NQe2en9kbUH/wY2IXaHgFLgKZtjWFmLcC1wGfcffXmWjPPSYUfTT8n3oMmrxH9EeyLgc33fwmbVfY17r64/v9y4Hr6t/POMjMbDVD/f3l/OOHuy+ovtI3AT2nSOTGzIdQC7OfuvqlRU9PPSZUf/XVO6sfuoJtNXiP6I9jvAybWVxaHAscDNzbbCTPbxsyGb3oMHAo8nI/qU26k1rgT+rGB56bgqnMMTTgnZmbAxcA8d//eZlJTz0nkR7PPSZ81eW3WCuOrVhuPpLbS+QTwxX7yYQK1TMBDwCPN9AO4ktrHwZeoffc6mdqeeXOA+cCtwPb95MfPgHZgLrVgG90EPw6k9hF9LvBg/d+RzT4niR9NPSfAXtSauM6l9sbylc1es/cCC4BfAFt2Z17dQSdEIZS+QCdEMSjYhSgEBbsQhaBgF6IQFOxCFIKCXYhCULALUQgKdiEK4f8B/cEcZqXQEuQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_set[0][0].permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644a659",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64ec050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8*8*32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # conv block         \n",
    "        x = self.conv_block(x)\n",
    "        \n",
    "        # classifier\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3040c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [1, 16, 32, 32]             448\n",
      "              ReLU-2            [1, 16, 32, 32]               0\n",
      "         MaxPool2d-3            [1, 16, 16, 16]               0\n",
      "            Conv2d-4            [1, 32, 16, 16]           4,640\n",
      "              ReLU-5            [1, 32, 16, 16]               0\n",
      "         MaxPool2d-6              [1, 32, 8, 8]               0\n",
      "           Flatten-7                  [1, 2048]               0\n",
      "            Linear-8                   [1, 512]       1,049,088\n",
      "              ReLU-9                   [1, 512]               0\n",
      "          Dropout-10                   [1, 512]               0\n",
      "           Linear-11                    [1, 64]          32,832\n",
      "             ReLU-12                    [1, 64]               0\n",
      "          Dropout-13                    [1, 64]               0\n",
      "           Linear-14                     [1, 2]             130\n",
      "       LogSoftmax-15                     [1, 2]               0\n",
      "================================================================\n",
      "Total params: 1,087,138\n",
      "Trainable params: 1,087,138\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.45\n",
      "Params size (MB): 4.15\n",
      "Estimated Total Size (MB): 4.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "summary(model, (3, 32, 32), batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739aeca1",
   "metadata": {},
   "source": [
    "### Initialize params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dfb56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "optimzer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8732b9a",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baac1c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.121948 %\n",
      "Epoch 1 loss 0.101016 %\n",
      "Epoch 2 loss 0.477697 %\n",
      "Epoch 3 loss 0.474845 %\n",
      "Epoch 4 loss 0.295752 %\n",
      "Epoch 5 loss 0.414453 %\n",
      "Epoch 6 loss 0.348943 %\n",
      "Epoch 7 loss 0.436883 %\n",
      "Epoch 8 loss 0.568099 %\n",
      "Epoch 9 loss 0.282434 %\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "def training_loops(n_epochs, model, train_loader, optimzer, loss_fn, verbose=1):\n",
    "    for epoch in range(n_epochs):\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            out = model(imgs)\n",
    "            loss = loss_fn(out, labels)\n",
    "\n",
    "            optimzer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimzer.step()\n",
    "\n",
    "        if epoch % verbose == 0:\n",
    "            print(f\"Epoch {epoch} loss {loss:3f} %\")\n",
    "\n",
    "model.train()\n",
    "training_loops(n_epochs, model, train_loader, optimzer, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a63297",
   "metadata": {},
   "source": [
    "### Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a60c46da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.886500 %\n",
      "Accuracy val: 0.856000 %\n"
     ]
    }
   ],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(f\"Accuracy {name}: {correct/total:3f} %\")\n",
    "\n",
    "model.eval()\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c7b3a",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2c38fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"bird_vs_airplane.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e054cb6",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5bac55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Net().to(device)\n",
    "loaded_model.load_state_dict(torch.load('bird_vs_airplane.pt'))\n",
    "\n",
    "# loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d42d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
