{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4cf46d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed4a0e",
   "metadata": {},
   "source": [
    "### Loading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf5fbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3799, 5698, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread('./img/sample1.jpeg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0b02c",
   "metadata": {},
   "source": [
    "### Changing the layout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af36c199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3799, 5698])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1) # H x W x C -> C x H x W\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00050542",
   "metadata": {},
   "source": [
    "### Load all image into a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b929c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8) # tensor holder for 3 images in 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf3c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"./img/\"\n",
    "file_names = [name for name in os.listdir(data_dir)]\n",
    "\n",
    "for i, file_name in enumerate(file_names):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, file_name)) # read the image\n",
    "    img_arr = np.resize(img_arr, (256, 256, 3)) # resize to fit in batch \n",
    "    img_t = torch.from_numpy(img_arr) # convert to tensor\n",
    "    img_t = img_t.permute(2, 0, 1) # change dim to C x H x W\n",
    "    img_t = img_t[:3] # select only 3 channels\n",
    "    batch[i] = img_t # assign to position i in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d6fac",
   "metadata": {},
   "source": [
    "### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4caa14c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batch.float() # convert to a float-tensor\n",
    "batch /= 255.0\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865743a",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f97d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 , 61.  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "wine_path = \"../data/tabular-wine/tabular-wine.csv\"\n",
    "wine_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
    "\n",
    "wine_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "598fefe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d02f9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol',\n",
       " 'quality']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=\";\"))\n",
    "\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "680a7220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 12])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_tensor = torch.from_numpy(wine_numpy)\n",
    "\n",
    "wine_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e31e33",
   "metadata": {},
   "source": [
    "### Representing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe2add20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wine_tensor[:, :-1] # select all rows and columns except the last column\n",
    "\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f88ab91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wine_tensor[:, -1] # select all rows and the last column\n",
    "target[-1] = 6.0\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d1d8648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 7, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = target.long()\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3e54f",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3364659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf010e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
